{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d83bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fedflax import train\n",
    "from models import ResNet\n",
    "from data import fetch_data\n",
    "from utils import angle_err, opt_create, return_l2, return_ce, top_5_err\n",
    "import jax, pickle\n",
    "from jax import numpy as jnp\n",
    "from flax import nnx\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "n_clients = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a782d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.key(42)\n",
    "vcall = nnx.jit(nnx.vmap(\n",
    "    lambda model, x: model(x, train=False), \n",
    "    in_axes=(0, None)\n",
    "))\n",
    "\n",
    "# For different distances, compute entanglement scores\n",
    "inducers = jnp.arange(20).tolist()\n",
    "distances = []\n",
    "logits = {\"logits_init\": [], \"logits_l\": [], \"logits_g\": [],\n",
    "          \"logits_l_rand\": [], \"logits_g_rand\": [], \"labels\": []}\n",
    "model_g = ResNet(key, dim_out=100)\n",
    "for inducer in inducers:\n",
    "    # Get datasets which induce this distance\n",
    "    ds_train = fetch_data(\"label\", beta=1., n_clients=n_clients, dataset=1, n_classes=100)\n",
    "    ds_test = fetch_data(\"label\", partition=\"test\", beta=1., n_clients=1, dataset=1, n_classes=100)\n",
    "    ds_val = fetch_data(\"label\", partition=\"val\", beta=1., n_clients=n_clients, dataset=1, n_classes=100)\n",
    "    # Get federated models which are this far apart\n",
    "    model_init = deepcopy(model_g)\n",
    "    fl_models, _ = train(model_g, partial(opt_create, learning_rate=1e-3), \n",
    "                      ds_train, return_ce(0.), ds_val, local_epochs=\"early\", \n",
    "                      max_patience=2, val_fn=top_5_err, rounds=1, n_clients=n_clients)\n",
    "    # Check entanglement wrt global model\n",
    "    struct, params_l, rest = nnx.split(fl_models, (nnx.Param, nnx.BatchStat), ...)\n",
    "    params_g = jax.tree.map(lambda p: p.mean(0), params_l)\n",
    "    model_g = nnx.merge(struct, params_g, rest)\n",
    "    # Get L2 distance\n",
    "    distance = jax.tree.map(lambda pg, pl: jnp.abs(pg - pl)**2, params_g, params_l)\n",
    "    distance = jax.tree.reduce(lambda acc, d: acc+jnp.sum(d.reshape(n_clients,-1), -1), distance, 0.)\n",
    "    distance = jnp.sqrt(distance.mean())\n",
    "    distances.append(distance.item())\n",
    "    # Get models which are (measured across all params) this far apart at random\n",
    "    rand_model_g = ResNet(key, dim_out=100)\n",
    "    rstate, rparams_g, rrest = nnx.split(rand_model_g, (nnx.Param, nnx.BatchStat), ...)\n",
    "    rand = jax.tree.map(\n",
    "        lambda p: jax.random.normal(key, (n_clients, *p.shape)), \n",
    "        rparams_g\n",
    "    )\n",
    "    norm = jnp.linalg.norm(\n",
    "        jnp.concatenate(jax.tree.map(lambda x: jnp.reshape(x, (n_clients,-1)), jax.tree.leaves(rand)), axis=1),\n",
    "        axis=-1\n",
    "    )\n",
    "    rparams_l = jax.tree.map(lambda p, r: p+(r.T/norm).T*distance, rparams_g, rand)\n",
    "    rand_models = nnx.merge(rstate, rparams_l, rrest)\n",
    "\n",
    "    # Now store logits to calculate entanglement\n",
    "    labels = jnp.empty((0,100))\n",
    "    logits_init = jnp.empty((0, 100))\n",
    "    logits_l = jnp.empty((n_clients, 0, 100))\n",
    "    logits_g = jnp.empty((0, 100))\n",
    "    logits_l_rand = jnp.empty((n_clients, 0, 100))\n",
    "    logits_g_rand = jnp.empty((0, 100))\n",
    "    for batch in ds_test:\n",
    "        labels = jnp.concatenate([labels, batch[0].squeeze(0)])\n",
    "        logits_l = jnp.concatenate([logits_l, vcall(fl_models, batch[1].squeeze(0))], axis=1)\n",
    "        logits_init = jnp.concatenate([logits_init, model_init(batch[1].squeeze(0), train=False)])\n",
    "        logits_g = jnp.concatenate([logits_g, model_g(batch[1].squeeze(0), train=False)])\n",
    "        logits_l_rand = jnp.concatenate([logits_l_rand, vcall(rand_models, batch[1].squeeze(0))], axis=1)\n",
    "        logits_g_rand = jnp.concatenate([logits_g_rand, rand_model_g(batch[1].squeeze(0), train=False)])\n",
    "    logits[\"logits_l\"].append(logits_l)\n",
    "    logits[\"logits_g\"].append(logits_g)\n",
    "    logits[\"logits_l_rand\"].append(logits_l_rand)\n",
    "    logits[\"logits_g_rand\"].append(logits_g_rand)\n",
    "    logits[\"logits_init\"].append(logits_init)\n",
    "    logits[\"labels\"].append(labels)\n",
    "    pickle.dump(logits, open(\"disentanglement/logits.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e910da",
   "metadata": {},
   "source": [
    "## Visualize entanglement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_entanglement_scores = [jnp.abs(logits[\"logits_l\"][i] - logits[\"logits_g\"][i]).mean().item() for i in range(len(inducers))] # TODO: models are currently tested on all data, not just their own\n",
    "rand_entanglement_scores = [jnp.abs(logits[\"logits_l_rand\"][i] - logits[\"logits_g_rand\"][i]).mean().item() for i in range(len(inducers))]\n",
    "\n",
    "# Matplotlib rendering style\n",
    "plt.style.use(\"seaborn-v0_8-pastel\")\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "    \"font.sans-serif\": [\"Helvetica\"],\n",
    "    \"text.latex.preamble\": r\"\"\"\n",
    "        \\usepackage{amsmath, amssymb}\n",
    "        \\usepackage{mathptmx}  % Safe fallback for Times + math\n",
    "    \"\"\"\n",
    "})\n",
    "\n",
    "# Plot entanglement vs distance\n",
    "fig, ax = plt.subplots();\n",
    "ax.plot(inducers, fl_entanglement_scores, label=\"FL models\", c=\"C0\");\n",
    "ax.plot(inducers, rand_entanglement_scores, label=\"Random models\", c=\"C1\");\n",
    "ax.set_xticks(inducers, labels=map(int, list(inducers)))\n",
    "ax.set_xlabel(\"Communication round\");\n",
    "ax.set_ylabel(\"Functional entanglement\");\n",
    "ax.legend();\n",
    "ax.set_xlim(min(inducers), max(inducers));\n",
    "ax.grid(True, linestyle=\"--\", linewidth=0.5);\n",
    "ax2 = ax.twiny();\n",
    "ax2.xaxis.set_ticks_position(\"bottom\");\n",
    "ax2.xaxis.set_label_position(\"bottom\");\n",
    "ax2.spines.bottom.set_position((\"outward\", 36));\n",
    "ax2.set_xlim(min(inducers), max(inducers));\n",
    "ax2.set_xticks(inducers, labels=map(lambda x: f\"{x:.1f}\", distances));\n",
    "ax2.set_xlabel(\"Euclidean parameter divergence\");\n",
    "fig.savefig(\"disentanglement/disentanglement.png\", dpi=300, bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2ce12",
   "metadata": {},
   "source": [
    "## Plot function over labels (ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3792b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert one-hot encoding to integer (identical for each round, given same test set)\n",
    "labels = logits[\"labels\"][-1].argmax(-1)\n",
    "# Function that returns the best guess out of top 5\n",
    "best_of_5 = lambda label, lgts: jnp.where(\n",
    "    jnp.any(label==jnp.argsort(lgts, axis=-1)[...,-5:], axis=-1),\n",
    "    label,\n",
    "    jnp.argmax(lgts, axis=-1)\n",
    ")\n",
    "# Function that returns the amount by which the correct label is displaced in the sorted logits (normalized by 10 for visibility)\n",
    "displacement = lambda label, lgts: jnp.argmax(jnp.argsort(lgts, axis=-1, descending=True)==label, axis=-1)/10\n",
    "# Plot\n",
    "fig, ax = plt.subplots();\n",
    "for i in range(n_clients):\n",
    "    # This indexation says: last round, client i, samples belonging to label, top logit, mean over samples\n",
    "    scoreperlabel = [best_of_5(label, logits[\"logits_l\"][-1][i,jnp.nonzero(labels==label)[0],:]).mean() for label in jnp.unique(labels)]\n",
    "    # This indexation says: all rounds, client i, samples belonging to label, top logit, mean over samples, std over rounds\n",
    "    stdperlabel = jnp.stack(logits[\"logits_l\"])\n",
    "    stdperlabel = [displacement(label, stdperlabel[:,i,jnp.nonzero(labels==label)[0],:]).mean((0,-1)) for label in jnp.unique(labels)]\n",
    "    # Plot mean line with shaded std\n",
    "    ax.hlines(scoreperlabel, jnp.arange(100), jnp.arange(1,101), colors=\"C\"+str(i), label=f\"Client {i}\")\n",
    "    ax.fill_between(jnp.unique(labels),\n",
    "                    jnp.array(scoreperlabel)-jnp.array(stdperlabel),\n",
    "                    jnp.array(scoreperlabel)+jnp.array(stdperlabel),\n",
    "                    color=\"C\"+str(i), alpha=0.3, step=\"post\", linewidth=0)\n",
    "    # Show domain\n",
    "    ax.axvspan(i*100/n_clients, (i+1)*100/n_clients, color=\"C\"+str(i), alpha=0.05, zorder=0)\n",
    "\n",
    "# Same for aggregated model\n",
    "scoreperlabel = [best_of_5(label, logits[\"logits_g\"][-1][jnp.nonzero(labels==label)[0],:]).mean() for label in jnp.unique(labels)]\n",
    "stdperlabel = jnp.stack(logits[\"logits_g\"])\n",
    "stdperlabel = [displacement(label, stdperlabel[:,jnp.nonzero(labels==label)[0],:]).mean((0,-1)) for label in jnp.unique(labels)]\n",
    "ax.hlines(scoreperlabel, jnp.arange(100), jnp.arange(1,101), colors=\"black\", label=\"Aggregated model\")\n",
    "ax.fill_between(jnp.unique(labels),\n",
    "                jnp.array(scoreperlabel)-jnp.array(stdperlabel),\n",
    "                jnp.array(scoreperlabel)+jnp.array(stdperlabel),\n",
    "                color=\"black\", alpha=0.3, step=\"post\", linewidth=0)\n",
    "\n",
    "# # ax.plot(labels, labels - outs_init, c=\"gray\", label=\"Ideal model\");\n",
    "# # ax.axhline(0., c=\"black\", linestyle=\"-.\", label=\"Relative initialization\");\n",
    "fig.legend(framealpha=1);\n",
    "ax.set_xlabel(\"Label\");\n",
    "ax.set_ylabel(r\"$\\mathbb{E}_{x\\in\\mathcal{D}_{\\text{label}}}[\\text{argmax}(f(\\theta_i, x))]$\")\n",
    "ax.set_xlim(0, 99);\n",
    "ax.set_ylim(0,99);\n",
    "ax.set_yticks(jnp.arange(0, 100), labels=[0]+[None]*48+[\"...\"]+[None]*49+[99])\n",
    "ax.set_xticks(jnp.arange(0, 100), labels=[0]+[None]*48+[\"...\"]+[None]*49+[99])\n",
    "# ax.grid(True, linestyle=\"--\", linewidth=0.5);\n",
    "fig.savefig(\"disentanglement/function.png\", dpi=300, bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32ec0f2",
   "metadata": {},
   "source": [
    "## Plot function over labels (MPIIGaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = jnp.rad2deg(jnp.arctan2(*logits[\"labels\"][0].T))\n",
    "sorter = jnp.argsort(labels)\n",
    "labels = labels[sorter]\n",
    "labels = jnp.convolve(labels, jnp.ones((100,))/100., mode=\"valid\")\n",
    "outs_l = jnp.rad2deg(jnp.arctan2(*logits[\"logits_l\"][-1].T))[sorter]\n",
    "outs_l = jnp.vectorize(lambda out: jnp.convolve(out, jnp.ones((100,))/100., mode=\"valid\"), signature=\"(n)->(m)\")(outs_l.T)\n",
    "std_l = jnp.stack(list(map(lambda arr: jnp.rad2deg(jnp.arctan2(*arr.T)), logits[\"logits_l\"]))).std(0)[sorter]\n",
    "std_l = jnp.vectorize(lambda out: jnp.convolve(out, jnp.ones((100,))/100., mode=\"valid\"), signature=\"(n)->(m)\")(std_l.T)\n",
    "outs_g = jnp.rad2deg(jnp.arctan2(*logits[\"logits_g\"][-1][sorter].T))\n",
    "outs_g = jnp.convolve(outs_g, jnp.ones((100,))/100., mode=\"valid\")\n",
    "std_g = jnp.stack(list(map(lambda arr: jnp.rad2deg(jnp.arctan2(*arr.T)), logits[\"logits_g\"]))).std(0)[sorter]\n",
    "std_g = jnp.convolve(std_g, jnp.ones((100,))/100., mode=\"valid\")\n",
    "# Plot\n",
    "fig, ax = plt.subplots();\n",
    "for i in range(n_clients):\n",
    "    ax.plot(labels, outs_l[i], c=\"C\"+str(i), label=f\"Client {i}\");\n",
    "    ax.fill_between(\n",
    "        labels, \n",
    "        outs_l[i]-std_l[i], \n",
    "        outs_l[i]+std_l[i], \n",
    "        color=\"C\"+str(i), \n",
    "        alpha=.6,\n",
    "        linewidth=0.\n",
    "    );\n",
    "    ax.axvspan(*[(-120, 0), (-180, -120), (0, 120)][i], alpha=.2, color=\"C\"+str(i), zorder=0);\n",
    "ax.plot(labels, outs_g, c=\"black\", label=\"Aggregated model\");\n",
    "ax.fill_between(\n",
    "    labels, \n",
    "    outs_g-std_g, \n",
    "    outs_g+std_g, \n",
    "    color=\"black\", \n",
    "    alpha=.4,\n",
    "    linewidth=0.\n",
    ");\n",
    "\n",
    "# ax.plot(labels, labels - outs_init, c=\"gray\", label=\"Ideal model\");\n",
    "# ax.axhline(0., c=\"black\", linestyle=\"-.\", label=\"Relative initialization\");\n",
    "ax.legend();\n",
    "ax.set_xlabel(\"Label (degrees)\");\n",
    "ax.set_ylabel(r\"$\\mathbb{E}_{x\\in\\mathcal{D}_{\\text{label}}}[f(\\theta_i, x)-f(\\bar{\\theta},x)]$\")\n",
    "ax.set_xlim(-180, 180);\n",
    "ax.grid(True, linestyle=\"--\", linewidth=0.5);\n",
    "fig.savefig(\"disentanglement/function.png\", dpi=300, bbox_inches=\"tight\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
