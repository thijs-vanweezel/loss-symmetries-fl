{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d83bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fedflax import train\n",
    "from models import LeNet\n",
    "from data import fetch_data\n",
    "from utils import angle_err, opt_create, return_l2\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from flax import nnx\n",
    "from tqdm.auto import tqdm\n",
    "from functools import reduce, partial\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a782d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement of functional interference between one client's update vs all updates\n",
    "entanglement_fn = nnx.jit(nnx.vmap(\n",
    "    lambda model_g, models, x, z: jnp.abs(model_g(x, z) - models(x, z)), \n",
    "    in_axes=(None, 0, 0, 0)\n",
    "))\n",
    "key = jax.random.key(42)\n",
    "\n",
    "# For different distances, compute entanglement scores\n",
    "inducers = [0., 0.00782, 0.01564, 0.024] + (jnp.linspace(jnp.sqrt(0.032), 1, 7)**2).tolist()\n",
    "distances = []\n",
    "fl_entanglement_scores = []\n",
    "rand_entanglement_scores = []\n",
    "for inducer in inducers:\n",
    "    # Get datasets which induce this distance\n",
    "    ds_train = fetch_data(\"feature\", beta=inducer)\n",
    "    ds_test = fetch_data(\"feature\", partition=\"test\", beta=inducer)\n",
    "    ds_val = fetch_data(\"feature\", partition=\"val\", beta=inducer)\n",
    "    # Get federated models which are this far apart\n",
    "    model_init = LeNet(key)\n",
    "    fl_models, _ = train(model_init, partial(opt_create, learning_rate=1e-3), \n",
    "                      ds_train, return_l2(0.), ds_val, local_epochs=\"early\", \n",
    "                      max_patience=5, val_fn=angle_err, rounds=1)\n",
    "    # Check entanglement wrt global model\n",
    "    struct, params_l, rest = nnx.split(fl_models, (nnx.Param, nnx.BatchStat), ...)\n",
    "    params_g = jax.tree.map(lambda p: p.mean(0), params_l)\n",
    "    model_g = nnx.merge(struct, params_g, rest)\n",
    "    fl_entanglement_scores.append(reduce(\n",
    "        lambda acc, batch: acc + entanglement_fn(model_g, fl_models, *batch[1:]).mean().item(), \n",
    "        ds_test,\n",
    "        0.\n",
    "    ) / len(ds_test))\n",
    "    # Get L2 distance\n",
    "    distance = jax.tree.map(lambda pg, pl: jnp.abs(pg - pl)**2, params_g, params_l)\n",
    "    distance = jax.tree.reduce(lambda acc, d: acc+jnp.sum(d.reshape(4,-1), -1), distance, 0.)\n",
    "    distance = jnp.sqrt(distance.mean())\n",
    "    distances.append(distance.item())\n",
    "    # Get models which are (measured across all params) this far apart at random\n",
    "    rand_model_g = LeNet(key)\n",
    "    rstate, rparams_g, rrest = nnx.split(rand_model_g, (nnx.State, nnx.Param), ...)\n",
    "    rand = jax.tree.map(\n",
    "        lambda p: jax.random.normal(key, (4, *p.shape)), \n",
    "        rparams_g\n",
    "    )\n",
    "    norm = jnp.linalg.norm(\n",
    "        jnp.concatenate(jax.tree.map(lambda x: jnp.reshape(x, (4,-1)), jax.tree.leaves(rand)), axis=1),\n",
    "        axis=-1\n",
    "    )\n",
    "    rparams_l = jax.tree.map(lambda p, r: p+(r.T/norm).T*distance, rparams_g, rand)\n",
    "    rand_models = nnx.merge(rstate, rparams_l, rrest)\n",
    "    # Now check if this disentanglement is better than random\n",
    "    rand_entanglement_scores.append(reduce(\n",
    "        lambda acc, batch: acc + entanglement_fn(rand_model_g, rand_models, *batch[1:]).mean().item(), \n",
    "        ds_test, \n",
    "        0.\n",
    "    ) / len(ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e910da",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib rendering style\n",
    "plt.style.use(\"seaborn-v0_8-pastel\")\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "    \"font.sans-serif\": [\"Helvetica\"],\n",
    "    \"text.latex.preamble\": r\"\"\"\n",
    "        \\usepackage{amsmath, amssymb}\n",
    "        \\usepackage{mathptmx}  % Safe fallback for Times + math\n",
    "    \"\"\"\n",
    "})\n",
    "\n",
    "# Plot entanglement vs distance\n",
    "distances, inducers, fl_entanglement_scores, rand_entanglement_scores = zip(*sorted(zip(distances, inducers, fl_entanglement_scores, rand_entanglement_scores)))\n",
    "fig, ax = plt.subplots();\n",
    "ax.plot(distances, fl_entanglement_scores, label=\"FL models\", c=\"C0\");\n",
    "ax.plot(distances, rand_entanglement_scores, label=\"Random models\", c=\"C1\");\n",
    "ax.set_xlabel(\"Euclidean Parameter Divergence\");\n",
    "ax.set_ylabel(\"Functional Entanglement\");\n",
    "ax.legend();\n",
    "ax.set_xlim(min(distances), max(distances));\n",
    "ax.grid(True, linestyle=\"--\", linewidth=0.5);\n",
    "ax2 = ax.twiny();\n",
    "ax2.xaxis.set_ticks_position(\"bottom\");\n",
    "ax2.xaxis.set_label_position(\"bottom\");\n",
    "ax2.spines.bottom.set_position((\"outward\", 36));\n",
    "ax2.set_xlim(min(distances), max(distances));\n",
    "ax2.set_xticks(distances, labels=inducers);\n",
    "ax2.set_xlabel(\"Inducer of divergence\");\n",
    "fig.savefig(\"disentanglement.png\", dpi=300, bbox_inches=\"tight\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
