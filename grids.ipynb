{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0781d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_deterministic_ops=true\"\n",
    "import optax, jax, numpy as np, pickle\n",
    "from flax import nnx\n",
    "from jax import numpy as jnp\n",
    "from vistool import pca_plot\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from fedflax import train\n",
    "from tqdm.auto import tqdm\n",
    "from data import get_gaze\n",
    "from models import ResNet\n",
    "n = 4 # number of clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ff7593",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e048f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "opt = lambda model: nnx.Optimizer(\n",
    "    model,\n",
    "    optax.adamw(learning_rate=1e-3),\n",
    "    wrt=nnx.Param\n",
    ")\n",
    "\n",
    "# Loss includes softmax layer\n",
    "def return_ell(omega):\n",
    "    def ell(model, model_g, x_batch, z_batch, y_batch, train):\n",
    "        prox = sum(jax.tree.map(lambda a, b: jnp.sum((a-b)**2), jax.tree.leaves(nnx.to_tree(model)), jax.tree.leaves(nnx.to_tree(model_g))))\n",
    "        ce = optax.softmax_cross_entropy(model(x_batch, z_batch, train=train), y_batch).mean()\n",
    "        return omega/2*prox + ce, (prox, ce)\n",
    "    return ell\n",
    "\n",
    "# For all beta-epoch settings\n",
    "for beta in [0.,.5,1.]:\n",
    "    # Create data\n",
    "    ds_train = get_gaze(beta=beta)\n",
    "    ds_val = get_gaze(beta=beta, partition=\"val\", batch_size=16)\n",
    "    for local_epochs in [3,9,27]:\n",
    "        # Optimize\n",
    "        train(ResNet(nnx.Rngs(42)), opt, ds_train, ds_val, return_ell(0.), local_epochs, f\"grids/MPIIGaze/params_omega{0.}_beta{beta}_local{local_epochs}.npy\", rounds=20, max_patience=5)\n",
    "\n",
    "# Three specific omega settings\n",
    "for omega in [.025,.1]:\n",
    "    # Create data\n",
    "    ds_train = get_gaze(beta=.5)\n",
    "    ds_val = get_gaze(beta=.5, partition=\"val\", batch_size=16)\n",
    "    # Optimize\n",
    "    train(ResNet(nnx.Rngs(42)), opt, ds_train, ds_val, return_ell(omega), 9, f\"grids/MPIIGaze/params_omega{omega}_beta{.5}_local{9}.npy\", rounds=20, max_patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6ad0e",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA model\n",
    "b = 50\n",
    "pca = IncrementalPCA(2, whiten=True, batch_size=b)\n",
    "# Fetch the beta-epoch parameters\n",
    "for beta in tqdm([1.,.5,0.]):\n",
    "    for epochs in tqdm([27,9,3], leave=False):\n",
    "        # Load params from entire trajectory and cut the patience epochs\n",
    "        fp = np.load(f\"grids/MPIIGaze/params_omega{0.}_beta{beta}_local{epochs}.npy\", mmap_mode=\"r\")[:-5*n*epochs] # 5 is patience\n",
    "        # Fit PCA (batch-wise due to memory constraints)\n",
    "        for batch in tqdm(np.array_split(fp, fp.shape[0]//b+1), leave=False):\n",
    "            pca = pca.partial_fit(batch)\n",
    "# Ditto for the omega settings\n",
    "for omega in tqdm([.025,.1]):\n",
    "    fp = np.load(f\"grids/MPIIGaze/params_omega{omega}_beta{.5}_local{9}.npy\", mmap_mode=\"r\")[:-5*n*9]\n",
    "    for batch in tqdm(np.array_split(fp, fp.shape[0]//b+1), leave=False):\n",
    "        pca = pca.partial_fit(batch)\n",
    "# Save PCA model\n",
    "pickle.dump(pca, open(\"pca.pkl\", \"wb\"))\n",
    "\n",
    "# Function to reconstruct model from flat params\n",
    "params, struct = jax.tree.flatten(nnx.to_tree(ResNet(nnx.Rngs(42))))\n",
    "shapes = [p.shape for p in params]+[None]\n",
    "def reconstruct(flat_params):\n",
    "    # Indices of kernels in flat vector\n",
    "    slices = [slice\n",
    "        (sum(map(lambda s: np.prod(s), shapes[:i])),\n",
    "        sum(map(lambda s: np.prod(s), shapes[:i+1])))\n",
    "    for i in range(len(shapes)-1)]\n",
    "    # Get kernels as correct shape\n",
    "    params = [flat_params[sl] for sl in slices]\n",
    "    params = [jnp.array(p).reshape(s) for p, s in zip(params, shapes)]\n",
    "    # Revert to model\n",
    "    return nnx.from_tree(jax.tree.unflatten(struct, params))\n",
    "\n",
    "# For each beta-epoch setting, plot PCA training trajectory\n",
    "pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
    "for beta in [0.,.5,1.]:\n",
    "    # Recreate data\n",
    "    ds_test = get_gaze(beta=beta, partition=\"test\", batch_size=16)\n",
    "    # Fix axes limits per local_epochs\n",
    "    paramses_trans = [pca.transform(np.load(f\"grids/MPIIGaze/params_omega{0.}_beta{beta}_local{epochs}.npy\", mmap_mode=\"r\")[:-5*n*epochs]) for epochs in [3,9,27]]\n",
    "    alpha_min, beta_min = min([p[:,0].min() for p in paramses_trans]), min([p[:,1].min() for p in paramses_trans])\n",
    "    alpha_max, beta_max = max([p[:,0].max() for p in paramses_trans]), max([p[:,1].max() for p in paramses_trans])\n",
    "    err_grid = None\n",
    "    for params_trans, epochs in zip(paramses_trans, [3,9,27]):\n",
    "        # Plot\n",
    "        model_idx = jnp.arange(params_trans.shape[0])%n\n",
    "        err_grid = pca_plot(pca, errs=err_grid, reduced_params=params_trans, beta_min=beta_min, beta_max=beta_max, \n",
    "                            alpha_max=alpha_max, alpha_min=alpha_min, model_idx=model_idx, ds=ds_test, reconstruct=reconstruct, \n",
    "                            filename=f\"grids/MPIIGaze/plot_beta{beta}_local{epochs}.png\", labels=False, epochs=epochs)\n",
    "\n",
    "# Plot PCA for each omega setting, at fixed beta and epochs\n",
    "ds_test = get_gaze(beta=.5, partition=\"test\", batch_size=16)\n",
    "# Fix axes limits per local_epochs\n",
    "paramses_trans = [pca.transform(np.load(f\"grids/MPIIGaze/params_omega{omega}_beta{.5}_local{9}.npy\", mmap_mode=\"r\")[:-5*n*9]) for omega in [0.,.025,.1]]\n",
    "alpha_min, beta_min = min([p[:,0].min() for p in paramses_trans]), min([p[:,1].min() for p in paramses_trans])\n",
    "alpha_max, beta_max = max([p[:,0].max() for p in paramses_trans]), max([p[:,1].max() for p in paramses_trans])\n",
    "err_grid = None\n",
    "for params_trans, omega in zip(paramses_trans, [0.,.025,.1]):\n",
    "    # Plot\n",
    "    model_idx = jnp.arange(params_trans.shape[0])%n\n",
    "    err_grid = pca_plot(pca, errs=err_grid, reduced_params=params_trans, beta_min=beta_min, beta_max=beta_max, \n",
    "                        alpha_max=alpha_max, alpha_min=alpha_min, model_idx=model_idx, ds=ds_test, reconstruct=reconstruct, \n",
    "                        filename=f\"grids/MPIIGaze/plot_omega{omega}.png\", labels=False, epochs=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
