{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8af5dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_deterministic_ops=true\"\n",
    "import jax, json, matplotlib as mpl, optax\n",
    "from jax import numpy as jnp\n",
    "from flax import nnx\n",
    "from models import LeNet\n",
    "from fedflax import train, aggregate, get_updates, cast\n",
    "from data import fetch_data\n",
    "from functools import reduce\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import return_l2, angle_err, functional_drift, nnx_norm\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "n_clients = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12722ec2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data \n",
    "ds_train = fetch_data(beta=1., skew=\"feature\", n_clients=n_clients)\n",
    "ds_val = fetch_data(partition=\"val\", beta=1., batch_size=32, skew=\"feature\", n_clients=n_clients)\n",
    "ds_test = fetch_data(partition=\"test\", beta=1., batch_size=16, skew=\"feature\", n_clients=n_clients)\n",
    "\n",
    "# Various settings to find conditions in which the asymmetry helps\n",
    "hypers_sweep:tuple[dict,...] = (\n",
    "    {},\n",
    "    {\"wasym\":True, \"kappa\":1.},\n",
    "    {\"sigma\":1e-4},\n",
    "    {\"normweights\":True},\n",
    "    {\"dimexp\":2},\n",
    "    {\"wasym\":True, \"kappa\":.1},\n",
    "    {\"sigma\":1e-3},\n",
    "    {\"dimexp\":4},\n",
    "    {\"wasym\":True, \"kappa\":5.},\n",
    "    {\"sigma\":5e-2},\n",
    "    {\"dimexp\":6}\n",
    ")\n",
    "\n",
    "# Perform a statistical test to assess whether regular round is worse than asym round\n",
    "def t_test(grid, mu_null=0., two_tailed:bool=True):\n",
    "    reg_gain = grid[:-1,:] - grid[1:,:] # i.e., error gain of step in direction of regular rounds\n",
    "    asym_gain = grid[:, :-1] - grid[:, 1:] # i.e., error gain of step in direction of asym rounds\n",
    "    diffs = reg_gain[:,:-1] - asym_gain[:-1,:] # i.e., difference between gain of reg round and asym round\n",
    "    diffs = jnp.fill_diagonal(diffs, jnp.nan, inplace=False) # otherwise would skew mu\n",
    "\n",
    "    mu = jnp.nanmean(diffs)\n",
    "    std = jnp.nanstd(diffs, ddof=1)\n",
    "    n = jnp.sum(~jnp.isnan(diffs))\n",
    "    t = (mu - mu_null) / std * jnp.sqrt(n)\n",
    "    p = (int(two_tailed)+1)*(1-stats.t.cdf(jnp.abs(t), df=n-1))\n",
    "\n",
    "    return {\"p-value\": p, \"df\": n-1, \"t-statistic\": t}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d06d790",
   "metadata": {},
   "source": [
    "# Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc928ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = defaultdict(lambda: defaultdict(list))\n",
    "for hypers in hypers_sweep:\n",
    "    # In case of syre, add wd\n",
    "    if \"sigma\" in hypers:\n",
    "        ell = lambda m, mg, y, x: return_l2(0.)(m, mg, y, x) + 1e-4*nnx_norm(nnx.state(m, nnx.Param), n_clients=n_clients).mean()\n",
    "    else: ell = return_l2(0.)\n",
    "    # Provide bounds on results\n",
    "    for seed in range(10):\n",
    "        # Train\n",
    "        model_init = LeNet(jax.random.key(seed), **hypers)\n",
    "        opt = nnx.Optimizer(model_init, optax.adam(1e-3), wrt=nnx.Param)\n",
    "        models, _ = train(model_init, opt, ds_train, ell, ds_val, local_epochs=\"early\", rounds=1, val_fn=angle_err, max_patience=5, n_clients=n_clients)\n",
    "        # Aggregate\n",
    "        state_l = nnx.state(models, (nnx.Param, nnx.BatchStat))\n",
    "        state_g = jax.tree.map(lambda p: p.mean(0), state_l)\n",
    "\n",
    "        # Calculate L1 and L2 distance from global model\n",
    "        e[str(hypers)][\"l2\"].append(nnx_norm(state_l, state_g, order=2., n_clients=n_clients).mean().item())\n",
    "        e[str(hypers)][\"l1\"].append(nnx_norm(state_l, state_g, order=1., n_clients=n_clients).mean().item())\n",
    "        vval_fn = nnx.jit(nnx.vmap(angle_err))\n",
    "        e[str(hypers)][\"angle_err\"].append(reduce(lambda e, batch: e + vval_fn(models, *batch), ds_test, jnp.zeros(n_clients)).mean().item() / len(ds_test))\n",
    "\n",
    "        # Save\n",
    "        json.dump(e, open(\"break/asym_hypers.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d266c6ec",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendering style\n",
    "plt.style.use(\"seaborn-v0_8-pastel\")\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],\n",
    "    \"font.sans-serif\": [\"Helvetica\"],\n",
    "    \"text.latex.preamble\": r\"\"\"\n",
    "        \\usepackage{amsmath, amssymb}\n",
    "        \\usepackage{mathptmx} \n",
    "    \"\"\"\n",
    "})\n",
    "\n",
    "def plot_as_grid(data:dict[int:dict[int:float]], filename:str):\n",
    "    fig, ax = plt.subplots(dpi=500);\n",
    "    # Determine grid size\n",
    "    y_ticks = list(data.keys())\n",
    "    x_ticks = max([set(subdict.keys()) for subdict in data.values()], key=len)\n",
    "    x_ticks = sorted(x_ticks, key=int)\n",
    "    grid = jnp.full((len(y_ticks), len(x_ticks)), jnp.nan, jnp.float32)\n",
    "    # Populate grid\n",
    "    for i, n_regular_rounds in enumerate(y_ticks):\n",
    "        for j, n_asym_rounds in enumerate(x_ticks):\n",
    "            # Set value, or NaN if missing\n",
    "            value = data[n_regular_rounds].get(n_asym_rounds, jnp.nan)\n",
    "            grid = grid.at[i, j].set(value)\n",
    "            # Simultaneously, plot the value as text\n",
    "            text = f\"{value:.2f}\" if not jnp.isnan(value) else \"\"\n",
    "            ax.text(j, i, text, ha=\"center\", va=\"center\", color=\"w\");\n",
    "\n",
    "    # Plot grid\n",
    "    cmap = plt.get_cmap(\"inferno\").with_extremes(bad=\"lightgray\");\n",
    "    ax.imshow(grid, cmap=cmap, norm=mpl.colors.LogNorm(vmin=3.66, vmax=15.5), interpolation=\"nearest\");\n",
    "    ax.set_xticks(range(len(x_ticks)), labels=[str(x) for x in x_ticks]);\n",
    "    ax.set_yticks(range(len(y_ticks)), labels=[str(y) for y in y_ticks]);\n",
    "    ax.set_ylabel(\"No. of conventional communication rounds performed in advance\");\n",
    "    ax.set_xlabel(\"No. of communication rounds subsequently\\nperformed with asymmetry applied\");\n",
    "    fig.savefig(filename.removesuffix(\".png\")+\".png\", bbox_inches=\"tight\");\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777f8c07",
   "metadata": {},
   "source": [
    "## Check metrics\n",
    "Available techniques are dimension expansion and W-Asymmetry, of which the latter is implemented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d96beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hypers in hypers_sweep:\n",
    "    # Track metrics\n",
    "    hypers_as_str = str(hypers)\n",
    "    test_errs_global = defaultdict(dict)\n",
    "    test_errs_local = defaultdict(dict)\n",
    "    drift = defaultdict(dict)\n",
    "    # In case of syre, add wd\n",
    "    if \"sigma\" in hypers:\n",
    "        ell = lambda m, mg, y, x: return_l2(0.)(m, mg, y, x) + 1e-4*nnx_norm(nnx.state(m, nnx.Param), n_clients=n_clients).mean()\n",
    "    else: ell = return_l2(0.)\n",
    "    # Initialize regular model\n",
    "    reg_model = LeNet(jax.random.key(42))\n",
    "    # Number of rounds is initialized to number required for early stopping\n",
    "    regular_roundses = jnp.array([(i+1)//2 for i in range(11)]).tolist()\n",
    "    for j in range(len(regular_roundses)):\n",
    "        # Federated training using regular model\n",
    "        if regular_roundses[j]:\n",
    "            opt = nnx.Optimizer(reg_model, optax.adam(1e-3), wrt=nnx.Param)\n",
    "            reg_models, _ = train(reg_model, opt, ds_train, ell, ds_val, local_epochs=\"early\", rounds=regular_roundses[j], val_fn=angle_err, max_patience=2, n_clients=n_clients)\n",
    "            reg_model = aggregate(reg_model, get_updates(reg_model, reg_models))\n",
    "        # Finalization of training using asymmetric model\n",
    "        asym_roundses = jnp.array([(i+1)//2 for i in range(11)]).tolist()\n",
    "        for i in range(len(asym_roundses)):\n",
    "            if i==1:\n",
    "                # Transfer parameters of the trained regular model to an asymmetric architecture\n",
    "                _, fc1reg, reg_params, _ = nnx.split(reg_model, nnx.All(nnx.PathContains(\"fc1\"), (nnx.Param, nnx.BatchStat)), (nnx.Param, nnx.BatchStat), ...)\n",
    "                asym_struct, fc1asym, _, rest = nnx.split(LeNet(**hypers), nnx.All(nnx.PathContains(\"fc1\"), (nnx.Param, nnx.BatchStat)), (nnx.Param, nnx.BatchStat), ...)\n",
    "                fc1 = fc1asym if \"dimexp\" in hypers else fc1reg\n",
    "                asym_model = nnx.merge(asym_struct, fc1, reg_params, rest)\n",
    "            if i==0:\n",
    "                asym_model = reg_model\n",
    "                asym_models = cast(reg_model, n_clients) if j==0 else reg_models\n",
    "            else:\n",
    "                # Train asymmetric\n",
    "                opt = nnx.Optimizer(asym_model, optax.adam(1e-3), wrt=nnx.Param)\n",
    "                asym_models, _ = train(asym_model, opt, ds_train, ell, ds_val, local_epochs=\"early\", rounds=asym_roundses[i], val_fn=angle_err, max_patience=2, n_clients=n_clients)\n",
    "                # Aggregate final models (the model passed as first arguments is technically irrelevant)\n",
    "                updates = get_updates(asym_model, asym_models)\n",
    "                asym_model = aggregate(asym_model, updates)                \n",
    "            # Accuracy on each client's data of aggregated model\n",
    "            vval_fn = nnx.jit(nnx.vmap(angle_err, in_axes=(None,0,0,0)))\n",
    "            err_test_global = reduce(lambda e, batch: e + vval_fn(asym_model, *batch), ds_test, 0.) / len(ds_test)\n",
    "            test_errs_global[sum(regular_roundses[:j+1])][sum(asym_roundses[:i+1])] = err_test_global.mean().item()\n",
    "            # Accuracy of local models\n",
    "            vval_fn = nnx.jit(nnx.vmap(angle_err))\n",
    "            err_test_local = reduce(lambda e, batch: e + vval_fn(asym_models, *batch), ds_test, 0.) / len(ds_test)\n",
    "            test_errs_local[sum(regular_roundses[:j+1])][sum(asym_roundses[:i+1])] = err_test_local.mean().item()\n",
    "            # Client drift measured in function space # TODO: doesn't make sense when training for multiple rounds\n",
    "            drift[sum(regular_roundses[:j+1])][sum(asym_roundses[:i+1])] = functional_drift(asym_models, ds_test).mean().item()\n",
    "            # Save intermediate results\n",
    "            json.dump(test_errs_global, open(f\"break/test_errs_global_{hypers_as_str}.json\", \"w\"))\n",
    "            json.dump(test_errs_local, open(f\"break/test_errs_local_{hypers_as_str}.json\", \"w\"))\n",
    "            json.dump(drift, open(f\"break/drift_{hypers_as_str}.json\", \"w\"))\n",
    "    # Plot results for this asymmetry setting\n",
    "    grid = plot_as_grid(test_errs_global, f\"break/test_errs_global_{hypers_as_str}.png\")\n",
    "    print(t_test(grid))\n",
    "    plot_as_grid(test_errs_local, f\"break/test_errs_local_{hypers_as_str}.png\")\n",
    "    plot_as_grid(drift, f\"break/drift_{hypers_as_str}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
