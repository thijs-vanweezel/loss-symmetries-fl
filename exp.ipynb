{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827add03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models import ResNet, LeNet\n",
    "from fedflax import train\n",
    "from data import get_gaze\n",
    "from flax import nnx\n",
    "import optax, jax\n",
    "\n",
    "def ell(model, _, x_batch, z_batch, y_batch, train):\n",
    "    ce = optax.softmax_cross_entropy(model(x_batch, z_batch, train=train), y_batch).mean()\n",
    "    return ce, (0., 0.)\n",
    "\n",
    "opt_create = lambda model: nnx.Optimizer(\n",
    "        model,\n",
    "        optax.adamw(learning_rate=1e-3),\n",
    "        wrt=nnx.Param)\n",
    "\n",
    "updates, models = train(\n",
    "    LeNet(nnx.Rngs(0)), \n",
    "    opt_create,\n",
    "    get_gaze(beta=.4),\n",
    "    get_gaze(beta=.4, partition=\"val\", batch_size=16),\n",
    "    local_epochs=10,\n",
    "    ell=ell,\n",
    "    rounds=2\n",
    ")\n",
    "\n",
    "print((updates[1]==updates[0]).all())\n",
    "l = jax.tree.leaves(nnx.to_tree(models.layers[1].conv2))[1]\n",
    "print((l[0]==l[1]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efbd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, jax, torch, torchvision\n",
    "# jax.config.update('jax_enable_x64', True)\n",
    "from jax import numpy as jnp\n",
    "from torch.utils.data import Dataset, DataLoader, default_collate\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d39ad99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Outputs equal after teleportation: True\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from models import LeNet\n",
    "from itertools import chain\n",
    "from flax import nnx\n",
    "\n",
    "def teleport_lenet(model, lower=1e-8, upper=1.):\n",
    "    # Extract params\n",
    "    model_tree = nnx.to_tree(model)\n",
    "    params, struct = jax.tree.flatten(model_tree)\n",
    "\n",
    "    # Assign tau to each output channel of each kernel\n",
    "    def random(size):\n",
    "        global key\n",
    "        _, key = jax.random.split(key)\n",
    "        return jax.random.uniform(key, size, minval=lower, maxval=upper)\n",
    "    tau = jax.tree.map(lambda p: random(p.shape[-1]), params[:-2:2])\n",
    "    # \"Input neurons\" require tau=1\n",
    "    tau_a = [jnp.ones(1)] + jax.tree.leaves(tau) \n",
    "    tau_a[2] = jnp.tile(tau_a[2], (6,12,1)).flatten() # Transition from conv to flattened fc\n",
    "    tau_a[2] = jnp.concat([tau_a[2], jnp.ones(3)])  # Account for auxiliary inputs\n",
    "    # Output neurons require tau=1\n",
    "    tau_b = jax.tree.leaves(tau) + [jnp.ones(16)]\n",
    "    coefs_kernel = jax.tree.map(lambda t_a, t_b: jnp.outer(1/t_a, t_b), tau_a, tau_b)\n",
    "\n",
    "    # Due to bias requiring tau=1, this is equivalent to tau + ones(channels_out)\n",
    "    coefs_bias = tau_b\n",
    "\n",
    "    # Interleave kernel and bias coefs, as they are originally\n",
    "    coefs = list(chain(*zip(coefs_bias, coefs_kernel)))\n",
    "    # Teleport the model\n",
    "    params_tele = jax.tree.map(lambda p, c: c*p, params, coefs)\n",
    "    # Rebuilt the model\n",
    "    return nnx.from_tree(jax.tree.unflatten(struct, params_tele))\n",
    "\n",
    "key = jax.random.key(42)\n",
    "model = LeNet(nnx.Rngs(key))\n",
    "rand_in = jax.random.normal(key, (1, 36, 60, 1))\n",
    "rand_aux = jax.random.normal(key, (1, 3))\n",
    "out_orig = model(rand_in, rand_aux)\n",
    "out_tele = teleport_lenet(model)(rand_in, rand_aux)\n",
    "print(\"Outputs equal after teleportation:\", jnp.allclose(out_orig, out_tele, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8920a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "(img, aux, label) = torch.load(\"MPIIGaze_preprocessed/train/p14/day06_49_right.pt\")\n",
    "imshape = torch.asarray(img.shape[1::-1])\n",
    "plt.imshow(torch.flip(img, [1]), cmap=\"gray\");\n",
    "plt.xticks([]); plt.yticks([]);\n",
    "# plt.scatter(*((all_labels+.5)*jnp.asarray(img.shape[1::-1])).T, alpha=.02, c=\"r\");\n",
    "regions = torch.concat([\n",
    "    torch.cartesian_prod(torch.linspace(-0.3675091, 0.0831264, 4), torch.linspace(-0.31378174, 0.38604215, 4)[:2]),\n",
    "    torch.cartesian_prod(torch.linspace(-0.3675091, 0.0831264, 4), torch.linspace(-0.31378174, 0.38604215, 4)[2:])\n",
    "])+.5\n",
    "plt.scatter(*(regions*imshape).T, c=\"b\");\n",
    "loc = torch.asarray([torch.arcsin(-label[1]), torch.arctan2(-label[0], -label[2])])+.5\n",
    "plt.scatter(loc[0]*imshape[0], loc[1]*imshape[1], c=\"y\");\n",
    "label = torch.abs(loc - regions).sum(axis=1).argmin()\n",
    "plt.scatter(*(regions[label]*imshape).T, c=\"purple\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_deterministic_ops=true\"\n",
    "# os.environ[\"JAX_DISABLE_MOST_FASTER_PATHS\"] = \"1\"\n",
    "from data import get_gaze\n",
    "import fedflax, jax, optax\n",
    "from fedflax import train\n",
    "from jax import numpy as jnp\n",
    "from models import ResNet\n",
    "from flax import nnx\n",
    "\n",
    "# Optimizer\n",
    "opt = lambda model: nnx.Optimizer(\n",
    "    model,\n",
    "    optax.adamw(learning_rate=1e-3),\n",
    "    wrt=nnx.Param\n",
    ")\n",
    "\n",
    "# # Identically initialized models, interpretable as collection by nnx \n",
    "# keys = nnx.vmap(lambda k: nnx.Rngs(k))(jnp.array([jax.random.key(42)]*4))\n",
    "# models = nnx.vmap(ResNet)(keys)\n",
    "# # Ditto for optimizers\n",
    "# opts = nnx.vmap(opt)(models)\n",
    "\n",
    "# @nnx.vmap\n",
    "# @nnx.value_and_grad\n",
    "# def ell(model, x_batch, z_batch, y_batch):\n",
    "#     y_pred = model(x_batch, z_batch, train=True)\n",
    "#     loss = optax.softmax_cross_entropy(y_pred, y_batch).mean()\n",
    "#     return loss\n",
    "def ell(model, model_g, x_batch, z_batch, y_batch, train):\n",
    "    y_pred = model(x_batch, z_batch, train=train)\n",
    "    loss = optax.softmax_cross_entropy(y_pred, y_batch).mean()\n",
    "    return loss, (0., 0.)\n",
    "\n",
    "train_ds = get_gaze(\"overlap\", beta=1.)\n",
    "# for x,z,y in train_ds:\n",
    "#     val, grad = ell(models, x, z, y)\n",
    "#     break\n",
    "\n",
    "train(ResNet, opt, train_ds, None, ell, local_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b33c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data import create_imagenet\n",
    "from matplotlib import pyplot as plt\n",
    "import jax, optax\n",
    "from jax import numpy as jnp\n",
    "from fedflax import train\n",
    "from flax import nnx\n",
    "from models import ResNet\n",
    "n=4\n",
    "\n",
    "ds_train = create_imagenet(n=n, feature_beta=.1)\n",
    "\n",
    "def ell(model, model_g, x_batch, y_batch):\n",
    "    ce = optax.softmax_cross_entropy(model(x_batch), y_batch).mean()\n",
    "    return ce, (0., ce)\n",
    "\n",
    "@nnx.jit\n",
    "@nnx.vmap(in_axes=(0,None,0,0,0))\n",
    "def train_step(model, model_g, opt, x_batch, y_batch):\n",
    "    (loss, (prox, ce)), grads = nnx.value_and_grad(ell, has_aux=True)(model, model_g, x_batch, y_batch)\n",
    "    # grads = jax.tree.map(lambda g: g/2**15, grads)\n",
    "    opt.update(grads)\n",
    "    return loss, grads\n",
    "\n",
    "# Optimizer\n",
    "opt = lambda model: nnx.Optimizer(\n",
    "    model,\n",
    "    optax.adamw(learning_rate=1e-3),\n",
    "    wrt=nnx.Param\n",
    ")\n",
    "\n",
    "# Identically initialized models, interpretable as collection by nnx \n",
    "keys = nnx.vmap(lambda k: nnx.Rngs(k))(jnp.array([jax.random.key(42)]*n))\n",
    "models = nnx.vmap(ResNet)(keys)\n",
    "# Ditto for optimizers\n",
    "opts = nnx.vmap(opt)(models)\n",
    "# Init and save\n",
    "params, struct = jax.tree.flatten(nnx.to_tree(models))\n",
    "model_g = nnx.from_tree(jax.tree.unflatten(struct, jax.tree.map(lambda x: jnp.mean(x, axis=0), params)))\n",
    "\n",
    "for x, y in ds_train:\n",
    "    loss, grads = train_step(models, model_g, opts, x, y)\n",
    "    print(loss)\n",
    "    if jnp.isnan(loss).any():\n",
    "        print(\"NaN encountered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a327866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as jnp\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import map_coordinates\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def perspective_shift(image, angle=0, skew_strength=0):\n",
    "    h, w = image.shape[:2]\n",
    "    src_pts = np.array([[0, 0], [w, 0], [0, h], [w, h]], dtype=np.float32)\n",
    "    dx = np.cos(angle) * skew_strength * w\n",
    "    dy = np.sin(angle) * skew_strength * h\n",
    "    dst_pts = np.array([\n",
    "        [0 + dx, 0],\n",
    "        [w + dx, 0 + dy],\n",
    "        [0 - dx, h],\n",
    "        [w - dx, h - dy]\n",
    "    ], dtype=np.float32)\n",
    "    transform = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    return cv2.warpPerspective(image, transform, (w, h))\n",
    "\n",
    "image = np.swapaxes(np.asarray(torchvision.io.read_image(\"/thesis/data/Data/CLS-LOC/train/n01534433/n01534433_47.JPEG\")), 0, -1)\n",
    "distorted_image = perspective_shift(image, angle=jnp.pi/4, skew_strength=1.2)\n",
    "plt.imshow(distorted_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
