{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ecde23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_deterministic_ops=true\"\n",
    "import jax, optax\n",
    "from jax import numpy as jnp\n",
    "from flax import nnx\n",
    "from models import LeNet, ResNet\n",
    "from fedflax import train, aggregate\n",
    "from data import get_gaze\n",
    "from functools import partial, reduce\n",
    "from utils import err_fn, opt_create, return_ce, return_l2, angle_err\n",
    "\n",
    "ds_train = get_gaze(beta=1., skew=\"feature\", discrete=False)\n",
    "ds_val = get_gaze(partition=\"val\", beta=1., batch_size=16, skew=\"feature\", discrete=False)\n",
    "ds_test = get_gaze(partition=\"test\", beta=1., batch_size=16, skew=\"feature\", discrete=False)\n",
    "\n",
    "model = LeNet(jax.random.key(42), wasym=\"random\", kappa=1, sigma=0., dim_out=2, dimexp=False)\n",
    "updates, models, opts = train(model, partial(opt_create, learning_rate=1e-3), ds_train, ds_val, return_l2(0.), local_epochs=20, rounds=1, val_fn=angle_err);\n",
    "\n",
    "model_g = aggregate(model, updates)\n",
    "vval_fn = nnx.jit(nnx.vmap(angle_err, in_axes=(None,0,0,0)))\n",
    "err_test = reduce(lambda e, batch: e + vval_fn(model_g,*batch), ds_test, 0.) / len(ds_test)\n",
    "err_val = reduce(lambda e, batch: e + vval_fn(model_g,*batch), ds_val, 0.) / len(ds_val)\n",
    "\n",
    "vval_fn = nnx.jit(nnx.vmap(angle_err, in_axes=(0,0,0,0)))\n",
    "err_sep_test = reduce(lambda e, batch: e + vval_fn(models,*batch), ds_test, 0.) / len(ds_test)\n",
    "err_sep_val = reduce(lambda e, batch: e + vval_fn(models,*batch), ds_val, 0.) / len(ds_val)\n",
    "\n",
    "print(err_test.mean(), err_val.mean(), err_sep_test.mean(), err_sep_val.mean())\n",
    "# regular: test ~11, val ~5\n",
    "# wasym: test ~12, val ~5\n",
    "# wasym kappa 10: test ~15, val ~28\n",
    "# wasym kappa .1: test ~11, val ~4\n",
    "# wasym kappa .01: test ~11, val ~4\n",
    "# wasym rand: test ~89, val ~90\n",
    "# syre 1e-3, wd 1e-3: test ~11, ~val 4\n",
    "# syre 1e-2, wd 1e-3: test ~63, val ~5\n",
    "# syre 1e-2, wd 1e-2: test ~66, val ~4\n",
    "# syre .1, wd 1e-3: test ~91, val ~6\n",
    "\n",
    "def angle(updates):\n",
    "    update_g = jax.tree.map(lambda updates: jnp.mean(updates, axis=0), updates)\n",
    "    update_g = jnp.concatenate([jnp.ravel(x) for x in update_g])\n",
    "    updates_flat = jnp.concatenate(jax.tree.map(lambda x: jnp.reshape(x, (4,-1)), updates), axis=1)\n",
    "    for update in updates_flat:\n",
    "        angle = jnp.degrees(jnp.arccos(optax.losses.cosine_similarity(update_g, update))).item()\n",
    "    return angle\n",
    "\n",
    "print(angle(jax.tree.leaves(updates)))\n",
    "# regular: ~57\n",
    "# wasym: ~55\n",
    "# wasym kappa 10: ~55\n",
    "# wasym kappa .1: ~56\n",
    "# wasym kappa .01: ~55\n",
    "# wasym rand: ~45\n",
    "# syre 1e-3, wd 1e-3: ~57\n",
    "# syre 1e-2, wd 1e-3: ~57\n",
    "# syre 1e-2, wd 1e-2: ~58\n",
    "# syre .1, wd 1e-3: ~57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827add03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models import ResNet, LeNet\n",
    "from fedflax import train\n",
    "from data import get_gaze\n",
    "from flax import nnx\n",
    "import optax, jax\n",
    "\n",
    "def ell(model, _, x_batch, z_batch, y_batch, train):\n",
    "    ce = optax.softmax_cross_entropy(model(x_batch, z_batch, train=train), y_batch).mean()\n",
    "    return ce, (0., 0.)\n",
    "\n",
    "opt_create = lambda model: nnx.Optimizer(\n",
    "        model,\n",
    "        optax.adamw(learning_rate=1e-3),\n",
    "        wrt=nnx.Param)\n",
    "\n",
    "updates, models = train(\n",
    "    LeNet(nnx.Rngs(0)), \n",
    "    opt_create,\n",
    "    get_gaze(beta=.4),\n",
    "    get_gaze(beta=.4, partition=\"val\", batch_size=16),\n",
    "    local_epochs=10,\n",
    "    ell=ell,\n",
    "    rounds=2\n",
    ")\n",
    "\n",
    "print((updates[1]==updates[0]).all())\n",
    "l = jax.tree.leaves(nnx.to_tree(models.layers[1].conv2))[1]\n",
    "print((l[0]==l[1]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efbd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, jax, torch, torchvision\n",
    "# jax.config.update('jax_enable_x64', True)\n",
    "from jax import numpy as jnp\n",
    "from torch.utils.data import Dataset, DataLoader, default_collate\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import product\n",
    "from data import get_gaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8920a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_gaze(beta=0., skew=\"feature\", discrete=False)\n",
    "# all_labels = []\n",
    "# for *_, y in ds:\n",
    "#     all_labels.append(y.reshape(-1,2))\n",
    "# all_labels = jnp.concatenate(all_labels)\n",
    "\n",
    "(img, aux, label) = torch.load(\"MPIIGaze_preprocessed/train/p14/day06_50_left.pt\")\n",
    "imshape = torch.asarray(img.shape[1::-1])\n",
    "plt.imshow(img, cmap=\"gray\");\n",
    "plt.xticks([]); plt.yticks([]);\n",
    "plt.scatter(*((all_labels+.5)*jnp.asarray(img.shape[1::-1])).T, alpha=.02, c=\"r\");\n",
    "nr = 3\n",
    "min_0, max_0, min_1, max_1 = -0.36719793, 0.3623084, -0.31378174, 0.38604215\n",
    "min_0, max_0, min_1, max_1 = min_0*(1-1/nr), max_0*(1-1/nr), min_1*(1-1/nr), max_1*(1-1/nr)\n",
    "regions = torch.concat([\n",
    "    torch.cartesian_prod(torch.linspace(min_0, max_0, nr), torch.linspace(min_1, max_1, nr)[:2]),\n",
    "    torch.cartesian_prod(torch.linspace(min_0, max_0, nr), torch.linspace(min_1, max_1, nr)[2:])\n",
    "])+.5\n",
    "plt.scatter(*(regions*imshape).T, c=\"b\");\n",
    "loc = torch.asarray([-torch.arcsin(-label[1]), torch.arctan2(-label[0], -label[2])])+.5\n",
    "plt.scatter(loc[0]*imshape[0], loc[1]*imshape[1], c=\"y\");\n",
    "label = torch.abs(loc - regions).sum(axis=1).argmin()\n",
    "plt.scatter(*(regions[label]*imshape).T, c=\"purple\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19742a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_gaze\n",
    "from jax import numpy as jnp\n",
    "ds = get_gaze(beta=0., partition=\"train\", discrete=True)\n",
    "label_dist = jnp.zeros(9)\n",
    "for *_, y in ds:\n",
    "    label_dist += y.sum((0,1))\n",
    "print(label_dist/label_dist.sum())\n",
    "\n",
    "# test = [0.08188657 0.1394676  0.1099537  0.15914352 0.09201389 0.13975695 0.08159722 0.11458334 0.08159722]\n",
    "# val = [0.0703125  0.140625   0.08203125 0.18359375 0.06640625 0.16015625 0.08203125 0.125      0.08984375]\n",
    "# train = [0.08195466 0.13985908 0.10753677 0.16881128 0.08869486 0.13449755 0.07628677 0.11764707 0.08471201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ad99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from models import LeNet, teleport_lenet\n",
    "from itertools import chain\n",
    "from flax import nnx\n",
    "\n",
    "model = LeNet(nnx.Rngs(key))\n",
    "rand_in = jax.random.normal(key, (1, 36, 60, 1))\n",
    "rand_aux = jax.random.normal(key, (1, 3))\n",
    "out_orig = model(rand_in, rand_aux)\n",
    "out_tele = teleport_lenet(model)(rand_in, rand_aux)\n",
    "print(\"Outputs equal after teleportation:\", jnp.allclose(out_orig, out_tele, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b5a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "fig, ax = plt.subplots(dpi=700)\n",
    "bar = fig.colorbar(plt.cm.ScalarMappable(norm=mpl.colors.Normalize(vmin=.5, vmax=1.), cmap=\"inferno\"), ax=ax, ticks=None)\n",
    "bar.set_label(\"Error Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os \n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_deterministic_ops=true\"\n",
    "# os.environ[\"JAX_DISABLE_MOST_FASTER_PATHS\"] = \"1\"\n",
    "from data import get_gaze\n",
    "import fedflax, jax, optax\n",
    "from fedflax import train\n",
    "from jax import numpy as jnp\n",
    "from models import ResNet\n",
    "from flax import nnx\n",
    "\n",
    "# Optimizer\n",
    "opt = lambda model: nnx.Optimizer(\n",
    "    model,\n",
    "    optax.adamw(learning_rate=1e-3),\n",
    "    wrt=nnx.Param\n",
    ")\n",
    "\n",
    "# # Identically initialized models, interpretable as collection by nnx \n",
    "# keys = nnx.vmap(lambda k: nnx.Rngs(k))(jnp.array([jax.random.key(42)]*4))\n",
    "# models = nnx.vmap(ResNet)(keys)\n",
    "# # Ditto for optimizers\n",
    "# opts = nnx.vmap(opt)(models)\n",
    "\n",
    "# @nnx.vmap\n",
    "# @nnx.value_and_grad\n",
    "# def ell(model, x_batch, z_batch, y_batch):\n",
    "#     y_pred = model(x_batch, z_batch, train=True)\n",
    "#     loss = optax.softmax_cross_entropy(y_pred, y_batch).mean()\n",
    "#     return loss\n",
    "def ell(model, model_g, x_batch, z_batch, y_batch, train):\n",
    "    y_pred = model(x_batch, z_batch, train=train)\n",
    "    loss = optax.softmax_cross_entropy(y_pred, y_batch).mean()\n",
    "    return loss, (0., 0.)\n",
    "\n",
    "train_ds = get_gaze(\"overlap\", beta=1.)\n",
    "# for x,z,y in train_ds:\n",
    "#     val, grad = ell(models, x, z, y)\n",
    "#     break\n",
    "\n",
    "train(ResNet, opt, train_ds, None, ell, local_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b33c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data import create_imagenet\n",
    "from matplotlib import pyplot as plt\n",
    "import jax, optax\n",
    "from jax import numpy as jnp\n",
    "from fedflax import train\n",
    "from flax import nnx\n",
    "from models import ResNet\n",
    "n=4\n",
    "\n",
    "ds_train = create_imagenet(n=n, feature_beta=.1)\n",
    "\n",
    "def ell(model, model_g, x_batch, y_batch):\n",
    "    ce = optax.softmax_cross_entropy(model(x_batch), y_batch).mean()\n",
    "    return ce, (0., ce)\n",
    "\n",
    "@nnx.jit\n",
    "@nnx.vmap(in_axes=(0,None,0,0,0))\n",
    "def train_step(model, model_g, opt, x_batch, y_batch):\n",
    "    (loss, (prox, ce)), grads = nnx.value_and_grad(ell, has_aux=True)(model, model_g, x_batch, y_batch)\n",
    "    # grads = jax.tree.map(lambda g: g/2**15, grads)\n",
    "    opt.update(grads)\n",
    "    return loss, grads\n",
    "\n",
    "# Optimizer\n",
    "opt = lambda model: nnx.Optimizer(\n",
    "    model,\n",
    "    optax.adamw(learning_rate=1e-3),\n",
    "    wrt=nnx.Param\n",
    ")\n",
    "\n",
    "# Identically initialized models, interpretable as collection by nnx \n",
    "keys = nnx.vmap(lambda k: nnx.Rngs(k))(jnp.array([jax.random.key(42)]*n))\n",
    "models = nnx.vmap(ResNet)(keys)\n",
    "# Ditto for optimizers\n",
    "opts = nnx.vmap(opt)(models)\n",
    "# Init and save\n",
    "params, struct = jax.tree.flatten(nnx.to_tree(models))\n",
    "model_g = nnx.from_tree(jax.tree.unflatten(struct, jax.tree.map(lambda x: jnp.mean(x, axis=0), params)))\n",
    "\n",
    "for x, y in ds_train:\n",
    "    loss, grads = train_step(models, model_g, opts, x, y)\n",
    "    print(loss)\n",
    "    if jnp.isnan(loss).any():\n",
    "        print(\"NaN encountered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a327866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as jnp\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import map_coordinates\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def perspective_shift(image, angle=0, skew_strength=0):\n",
    "    h, w = image.shape[:2]\n",
    "    src_pts = np.array([[0, 0], [w, 0], [0, h], [w, h]], dtype=np.float32)\n",
    "    dx = np.cos(angle) * skew_strength * w\n",
    "    dy = np.sin(angle) * skew_strength * h\n",
    "    dst_pts = np.array([\n",
    "        [0 + dx, 0],\n",
    "        [w + dx, 0 + dy],\n",
    "        [0 - dx, h],\n",
    "        [w - dx, h - dy]\n",
    "    ], dtype=np.float32)\n",
    "    transform = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    return cv2.warpPerspective(image, transform, (w, h))\n",
    "\n",
    "image = np.swapaxes(np.asarray(torchvision.io.read_image(\"/thesis/data/Data/CLS-LOC/train/n01534433/n01534433_47.JPEG\")), 0, -1)\n",
    "distorted_image = perspective_shift(image, angle=jnp.pi/4, skew_strength=1.2)\n",
    "plt.imshow(distorted_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
