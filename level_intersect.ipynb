{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c59e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_deterministic_ops=true\"\n",
    "import optax, jax, numpy as np, pickle\n",
    "from flax import nnx\n",
    "from jax import numpy as jnp\n",
    "from sklearn.decomposition import PCA\n",
    "from fedflax import train\n",
    "from data import get_gaze\n",
    "from models import LeNet, ResNet\n",
    "from functools import reduce\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "opt_create = lambda model: nnx.Optimizer(\n",
    "    model,\n",
    "    optax.adamw(learning_rate=1e-3),\n",
    "    wrt=nnx.Param\n",
    ")\n",
    "\n",
    "# Loss includes softmax layer\n",
    "def ell(model, _, x_batch, z_batch, y_batch, train):\n",
    "    ce = optax.softmax_cross_entropy(model(x_batch, z_batch, train=train), y_batch).mean()\n",
    "    return ce, (0., 0.)\n",
    "\n",
    "# Train\n",
    "ds_train = get_gaze(beta=.5)\n",
    "ds_val = get_gaze(beta=.5, partition=\"val\")\n",
    "_, models = train(ResNet, opt_create, ds_train, ds_val, ell, local_epochs=50, rounds=1)\n",
    "paramses, struct = jax.tree.flatten(nnx.to_tree(models))\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2, whiten=True)\n",
    "paramses_trans = pca.fit_transform(\n",
    "    np.concat([p.reshape(4,-1) for p in paramses], axis=1)\n",
    ")\n",
    "\n",
    "# Function to reconstruct model from flat params\n",
    "shapes = [p.shape[1:] for p in paramses]+[None]\n",
    "def reconstruct(flat_params):\n",
    "    # Indices of kernels in flat vector\n",
    "    slices = [slice\n",
    "        (sum(map(lambda s: np.prod(s), shapes[:i])),\n",
    "        sum(map(lambda s: np.prod(s), shapes[:i+1])))\n",
    "    for i in range(len(shapes)-1)]\n",
    "    # Get kernels as correct shape\n",
    "    params = [flat_params[sl] for sl in slices]\n",
    "    params = [jnp.array(p).reshape(s) for p, s in zip(params, shapes)]\n",
    "    # Revert to model\n",
    "    return nnx.from_tree(jax.tree.unflatten(struct, params))\n",
    "\n",
    "# Set up grid for error surface\n",
    "points = 30\n",
    "x_min, x_max = paramses_trans[:, 0].min(), paramses_trans[:, 0].max()\n",
    "y_min, y_max = paramses_trans[:, 1].min(), paramses_trans[:, 1].max()\n",
    "alpha_grid = jnp.linspace(x_min-1/4*jnp.abs(x_min), x_max+1/4*jnp.abs(x_max), points)\n",
    "beta_grid = jnp.linspace(y_min-1/4*jnp.abs(y_min), y_max+1/4*jnp.abs(y_max), points)\n",
    "errs = jnp.zeros((points, points, 4))\n",
    "# For sampled points on the 2d plane, compute the accuracy\n",
    "ds_test = get_gaze(beta=.5, partition=\"test\")\n",
    "acc_fn = nnx.jit(nnx.vmap(lambda m,x,z,y: (m(x,z,train=False).argmax(-1)==y.argmax(-1)).mean(), in_axes=(None,0,0,0)))\n",
    "for i, alpha in enumerate(alpha_grid):\n",
    "    for j, beta in enumerate(beta_grid):\n",
    "        # Reconstruct the model for some point in the 2d plane\n",
    "        params = pca.inverse_transform(jnp.array([[alpha, beta]])).reshape(-1)\n",
    "        models = reconstruct(params)\n",
    "        # Compute accuracy\n",
    "        acc = reduce(lambda acc, b: acc + acc_fn(models,*b), ds_test, 0.) / len(ds_test)\n",
    "        errs = errs.at[i,j,:].set(1-acc) # do not take mean over clients\n",
    "\n",
    "# Contour plot\n",
    "fig, ax  = plt.subplots(dpi=300)\n",
    "levels = jnp.log(jnp.linspace(jnp.exp(errs.min()), jnp.exp(errs.max()), 10))\n",
    "colors = [\"blue\", \"red\", \"yellow\", \"green\"]\n",
    "for i in range(errs.shape[-1]):\n",
    "    # Make sure the optimum is displayed as a contour\n",
    "    optimum = errs[jnp.abs(alpha_grid - paramses_trans[i,0]).argmin(), jnp.abs(beta_grid - paramses_trans[i,1]).argmin(), i]\n",
    "    levels = jnp.log(jnp.linspace(jnp.exp(errs[...,i].min()), jnp.exp(optimum), 4))\n",
    "    # Opacity increases with accuracy\n",
    "    cmap = jnp.repeat(mpl.colors.to_rgba_array(colors[i]), 256, axis=0)\n",
    "    cmap = cmap.at[:,-1].set(jnp.linspace(0,1/4,256))\n",
    "    cmap = mpl.colors.LinearSegmentedColormap.from_list(name=f\"C{i}_alpha\", colors=cmap.tolist())\n",
    "    # Plot\n",
    "    ax.contourf(\n",
    "        alpha_grid,\n",
    "        beta_grid,\n",
    "        errs[...,i].T,\n",
    "        levels=levels,\n",
    "        cmap=cmap,\n",
    "        norm=mpl.colors.LogNorm(vmin=errs[...,i].min(), vmax=errs[...,i].max())\n",
    "    )\n",
    "# Plot the optima\n",
    "ax.scatter(\n",
    "    *paramses_trans.T,\n",
    "    c=[colors[i] for i in range(errs.shape[-1])],\n",
    ")\n",
    "ax.set_xticks([]);\n",
    "ax.set_yticks([]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
